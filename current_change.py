# -*- coding: utf-8 -*-
"""current change

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/leenammta/current-change.fe43181c-8f98-446e-ac2f-3cc878c12ebb.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20250523/auto/storage/goog4_request%26X-Goog-Date%3D20250523T081538Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Dccc1ee21e2ad6dbb3cef7121132c9363c00c89d123963f7acbdda50bb504360acc666135caff7cfe969f205367ce11b8448688b9a394c72b00e6b9b91f2e8e48a8e2672fb1a5d2689223224ac7820da697b957bdb43a18bf4189798e79bf4d50776f951b0deacb6b4190d2aeec80469ebfbcc1b1c3fbcd48ab6a62b067929d5eed144f27a6294eda738720ece6e151f4144945ba07a71d88a78fde1d2680de5ab4c0a3cc6df5f10be771ae0156d4fa64f1dcaec67c64efecc1ff89da04b4a5ea15bb83088cc724eef2745d439458aeb77b710a4723af50889c686a0b2cc8a2632db8239d2d6ac6993b57fbf86c6f3935444077e7c1e5726636860ba42b1add9c
"""

# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE
# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.
import kagglehub
kagglehub.login()

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.

leenammta_output1_path = kagglehub.dataset_download('leenammta/output1')

print('Data source import complete.')

!pip install numpy pandas statsmodels tensorflow keras xgboost scikit-learn matplotlib streamlit  random

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from xgboost import XGBRegressor
import random
import tensorflow as tf

# ==== Cá»‘ Ä‘á»‹nh seed Ä‘á»ƒ tÃ¡i láº­p káº¿t quáº£ ====
seed = 42
os.environ['PYTHONHASHSEED'] = str(seed)
np.random.seed(seed)
random.seed(seed)
tf.random.set_seed(seed)

# ==== Äá»c dá»¯ liá»‡u ====
df = pd.read_excel("/kaggle/input/output1/Data system POC_11Nov2024(mod).xlsx", sheet_name="Data- refinitiv")
df_actual = pd.read_excel("/kaggle/input/output1/Data system POC_11Nov2024(mod).xlsx", sheet_name="Sheet2")

# ==== Xá»­ lÃ½ dá»¯ liá»‡u ====
df["Date"] = pd.to_datetime(df["Date"])
df_actual["Date"] = pd.to_datetime(df_actual["Date"])
df.sort_values("Date", inplace=True)
df = df.fillna(df.mean(numeric_only=True))

df_actual["VND"] = (df_actual["VND"]
                    .astype(str)
                    .str.replace(" ", "")
                    .astype(float))

df.set_index("Date", inplace=True)

# ==== Äá»‹nh nghÄ©a láº¡i cá»™t vá»›i VND á»Ÿ vá»‹ trÃ­ thá»© 3 ====
features = ['FEDRATE', 'DXY', 'VND', 'OMOrate', 'SBVcentralrate']  # VND á»Ÿ index = 2
scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(df[features])

# ==== Táº¡o hÃ m xá»­ lÃ½ dá»¯ liá»‡u dáº¡ng sliding window ====
def create_sliding_window_data(data, window_size=20):
    X, y = [], []
    for i in range(window_size, len(data)):
        X.append(data[i-window_size:i, [0, 1, 3, 4]])  # exclude VND (index=2)
        y.append(data[i, 2])  # target lÃ  VND
    return np.array(X), np.array(y)

# ==== HÃ m dá»± bÃ¡o autoregressive báº±ng XGBoost ====
def xgb_autoregressive_forecast(scaled_data, df, scaler, n_days=7, window_size=20):
    X, y = create_sliding_window_data(scaled_data, window_size)
    X = X.reshape((X.shape[0], X.shape[1] * X.shape[2]))  # flatten

    split_index = np.where(df.index.year >= 2024)[0][0] - window_size
    X_train, y_train = X[:split_index], y[:split_index]

    # Huáº¥n luyá»‡n mÃ´ hÃ¬nh XGBoost
    model = XGBRegressor(n_estimators=600, learning_rate=0.9, max_depth=10)
    model.fit(X_train, y_train)

    # Dá»± bÃ¡o autoregressive
    forecast = []
    last_window = scaled_data[-window_size:].copy()

    for _ in range(n_days):
        input_data = np.delete(last_window, 2, axis=1)  # bá» cá»™t VND
        input_flat = input_data.reshape(1, -1)
        pred_scaled = model.predict(input_flat)[0]

        # Táº¡o dÃ²ng má»›i vá»›i VND dá»± bÃ¡o táº¡i cá»™t index=2
        new_row = last_window[-1].copy()
        new_row[2] = pred_scaled
        last_window = np.vstack([last_window[1:], new_row])
        forecast.append(new_row)

    forecast = np.array(forecast)
    forecast_inversed = scaler.inverse_transform(forecast)[:, 2]  # láº¥y láº¡i VND tá»« cá»™t thá»© 3
    return forecast_inversed

# ==== Gá»i hÃ m dá»± bÃ¡o ====
n_days = 7
xgb_pred = xgb_autoregressive_forecast(scaled_data, df, scaler, n_days=n_days, window_size=20)

# ==== Táº¡o máº£ng ngÃ y tÆ°Æ¡ng á»©ng Ä‘á»ƒ hiá»ƒn thá»‹ ====
forecast_dates = pd.date_range(start=df_actual["Date"].iloc[0], periods=n_days + 1, freq='D')[1:]


# ==== Hiá»ƒn thá»‹ báº£ng káº¿t quáº£ ====
print("### ðŸ“Š Káº¿t quáº£ dá»± bÃ¡o XGBoost:")
print("NgÃ y       | Dá»± bÃ¡o   | Xu hÆ°á»›ng | % Thay Ä‘á»•i")
print("-------------------------------------------")

for i in range(1, n_days):
    date_str = forecast_dates[i].strftime("%d-%m-%Y")
    prev_value = xgb_pred[i - 1]
    curr_value = xgb_pred[i]
    change_percent = ((curr_value - prev_value) / prev_value) * 100
    trend = "ðŸ“ˆ Up" if curr_value > prev_value else "ðŸ“‰ Down"
    print(f"{date_str} | {curr_value:.2f} | {trend} | {change_percent:.2f}%")

# ==== Váº½ biá»ƒu Ä‘á»“ káº¿t quáº£ ====
plt.figure(figsize=(12, 6))
plt.plot(forecast_dates, df_actual["VND"][:n_days].values, label="Thá»±c táº¿", color="blue")
plt.plot(forecast_dates, xgb_pred, label="XGBoost", linestyle="dashed", color="purple")
plt.xlabel("NgÃ y")
plt.ylabel("Tá»· giÃ¡ VND-USD")
plt.title("Dá»± bÃ¡o tá»· giÃ¡ VND-USD (Autoregressive XGBoost - VND á»Ÿ cá»™t 3)")
plt.legend()
plt.grid(True)
plt.show()